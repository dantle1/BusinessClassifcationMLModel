{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntokenizer = BertTokenizer.from_pretrained(\\'bert-base-cased\\')\\n\\nexample_text = \\'I will watch Memento tonight\\'\\nbert_input = tokenizer(example_text,padding=\\'max_length\\', max_length = 10, \\n                       truncation=True, return_tensors=\"pt\")\\n\\n\\nprint(bert_input[\\'input_ids\\'])\\nprint(bert_input[\\'token_type_ids\\'])\\nprint(bert_input[\\'attention_mask\\'])\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "'''\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "example_text = 'I will watch Memento tonight'\n",
    "bert_input = tokenizer(example_text,padding='max_length', max_length = 10, \n",
    "                       truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "print(bert_input['input_ids'])\n",
    "print(bert_input['token_type_ids'])\n",
    "print(bert_input['attention_mask'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = 'I will watch Memento tonight'\n",
    "bert_input = tokenizer(example_text,padding='max_length', max_length = 10, \n",
    "                       truncation=True, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {'traffic':0,\n",
    "          'entertainment':1\n",
    "          }\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['category']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_json('/Users/noarapoport/Documents/GitHub/final_50k_221118.json',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df1.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df1)), int(.9*len(df1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90da1de3ec9f46a4943671235b3d6628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zt/3z6q8x1d1zjffbdqfbv3hw800000gn/T/ipykernel_29513/3164186233.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/zt/3z6q8x1d1zjffbdqfbv3hw800000gn/T/ipykernel_29513/193878874.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dropout)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBertClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-cased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2448\u001b[0m                         \u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcommit_hash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m                     }\n\u001b[0;32m-> 2450\u001b[0;31m                     \u001b[0mresolved_archive_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcached_file_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m                     \u001b[0;31m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mresume_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         )\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1335\u001b[0m                 \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m                 \u001b[0mresume_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1337\u001b[0;31m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1338\u001b[0m             )\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetEffectiveLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTSET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     )\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m                 \u001b[0mflush_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;31m# StringIO doesn't like amt=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "                  \n",
    "EPOCHS = 5\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "              \n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6072c1517f7d444c85a4283c345ea73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54dd17d0f4c4b2c82589f3de60ced46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd21f891018544c98165c2ce7556ac4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e3d3d61a71458591a0491cb86f51a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df3       awesome_biz_id                                            content  \\\n",
      "0         biz_000003  They do not make authentic Italian calzones. O...   \n",
      "1         biz_000005  They are scammers!!! DO NOT BUY PRODUCTS FROM ...   \n",
      "2         biz_000009  Just opened the paper bag to find a burnt croi...   \n",
      "3         biz_000014  Needed a quick car wash!!! In the sign $4.19 i...   \n",
      "4         biz_000020  This service is convenient, easy, and fast. Li...   \n",
      "...              ...                                                ...   \n",
      "18719     biz_049988  Vonsland! I swear, THIS IS ACTUALLY A SMALL TO...   \n",
      "18720     biz_049993  This is a fun place to relax, create a paintin...   \n",
      "18721     biz_049994  3 stars for food and service. I have a friend ...   \n",
      "18722     biz_049995  It's wasn't bad as all. It's very slow and eve...   \n",
      "18723     biz_049999  Great selection.. lots of high end options.. b...   \n",
      "\n",
      "                    business_name  is_entertainment  is_traffic  \n",
      "0                         Calzone             False        True  \n",
      "1               cheebapotshop.com              True        True  \n",
      "2                 Perk Coffee Bar             False        True  \n",
      "3                 MB KAZMO OIL CO             False        True  \n",
      "4                  Wash-N-Deliver             False        True  \n",
      "...                           ...               ...         ...  \n",
      "18719         Lucky Liquor Market             False       False  \n",
      "18720             Pinot's Palette             False       False  \n",
      "18721                    Diem Hen             False       False  \n",
      "18722        Empire Hookah Lounge              True       False  \n",
      "18723  Minute Shops Liquor & Deli              True       False  \n",
      "\n",
      "[18724 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_shuffled = df1.sample(frac=1, random_state=39)\n",
    "\n",
    "# Reset the index\n",
    "df_shuffled = df_shuffled.reset_index(drop=True)\n",
    "\n",
    "df2 = df_shuffled[0:30000]\n",
    "#print(df2)\n",
    "#Select first 50000 rows\n",
    "\n",
    "#past = time.time()\n",
    "df3 = df2.groupby(df2[\"awesome_biz_id\"],as_index=False).agg({\"content\":' '.join,\"business_name\":\"first\",\"is_entertainment\":\"first\",\"is_traffic\":\"first\"})\n",
    "#now = time.time()\n",
    "#print(now-past)\n",
    "#print(df_new[\"business_name\"])\n",
    "print(\"df3\",df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1537949238.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/zt/3z6q8x1d1zjffbdqfbv3hw800000gn/T/ipykernel_2852/1537949238.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df1['label'] = np.where(df['is_entertainment'] == True && df['is_traffic]', 1, 0)\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df1['label'] = np.where(df['is_entertainment'] == True && df['is_traffic]', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df1\n",
    "target_names=dataset.target_names\n",
    "news_text = dataset.data\n",
    "labels = dataset.target\n",
    "(train_texts,valid_texts,train_labels,valid_labels)=train_test_split(news_text, labels, test_size=0.3)\n",
    "\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df3       awesome_biz_id                                            content  \\\n",
      "0         biz_000003  They do not make authentic Italian calzones. O...   \n",
      "1         biz_000005  They are scammers!!! DO NOT BUY PRODUCTS FROM ...   \n",
      "2         biz_000009  Just opened the paper bag to find a burnt croi...   \n",
      "3         biz_000014  Needed a quick car wash!!! In the sign $4.19 i...   \n",
      "4         biz_000020  This service is convenient, easy, and fast. Li...   \n",
      "...              ...                                                ...   \n",
      "18719     biz_049988  Vonsland! I swear, THIS IS ACTUALLY A SMALL TO...   \n",
      "18720     biz_049993  This is a fun place to relax, create a paintin...   \n",
      "18721     biz_049994  3 stars for food and service. I have a friend ...   \n",
      "18722     biz_049995  It's wasn't bad as all. It's very slow and eve...   \n",
      "18723     biz_049999  Great selection.. lots of high end options.. b...   \n",
      "\n",
      "                    business_name  is_entertainment  is_traffic  \n",
      "0                         Calzone             False        True  \n",
      "1               cheebapotshop.com              True        True  \n",
      "2                 Perk Coffee Bar             False        True  \n",
      "3                 MB KAZMO OIL CO             False        True  \n",
      "4                  Wash-N-Deliver             False        True  \n",
      "...                           ...               ...         ...  \n",
      "18719         Lucky Liquor Market             False       False  \n",
      "18720             Pinot's Palette             False       False  \n",
      "18721                    Diem Hen             False       False  \n",
      "18722        Empire Hookah Lounge              True       False  \n",
      "18723  Minute Shops Liquor & Deli              True       False  \n",
      "\n",
      "[18724 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_shuffled = df1.sample(frac=1, random_state=39)\n",
    "\n",
    "# Reset the index\n",
    "df_shuffled = df_shuffled.reset_index(drop=True)\n",
    "\n",
    "df2 = df_shuffled[0:30000]\n",
    "#print(df2)\n",
    "#Select first 50000 rows\n",
    "\n",
    "#past = time.time()\n",
    "df3 = df2.groupby(df2[\"awesome_biz_id\"],as_index=False).agg({\"content\":' '.join,\"business_name\":\"first\",\"is_entertainment\":\"first\",\"is_traffic\":\"first\"})\n",
    "#now = time.time()\n",
    "#print(now-past)\n",
    "#print(df_new[\"business_name\"])\n",
    "print(\"df3\",df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       is_entertainment  is_traffic\n",
      "0                 False        True\n",
      "1                  True        True\n",
      "2                 False        True\n",
      "3                 False        True\n",
      "4                 False        True\n",
      "...                 ...         ...\n",
      "18719             False       False\n",
      "18720             False       False\n",
      "18721             False       False\n",
      "18722              True       False\n",
      "18723              True       False\n",
      "\n",
      "[18724 rows x 2 columns]\n",
      "                    business_name  \\\n",
      "0                         Calzone   \n",
      "1               cheebapotshop.com   \n",
      "2                 Perk Coffee Bar   \n",
      "3                 MB KAZMO OIL CO   \n",
      "4                  Wash-N-Deliver   \n",
      "...                           ...   \n",
      "18719         Lucky Liquor Market   \n",
      "18720             Pinot's Palette   \n",
      "18721                    Diem Hen   \n",
      "18722        Empire Hookah Lounge   \n",
      "18723  Minute Shops Liquor & Deli   \n",
      "\n",
      "                                                 content  \n",
      "0      They do not make authentic Italian calzones. O...  \n",
      "1      They are scammers!!! DO NOT BUY PRODUCTS FROM ...  \n",
      "2      Just opened the paper bag to find a burnt croi...  \n",
      "3      Needed a quick car wash!!! In the sign $4.19 i...  \n",
      "4      This service is convenient, easy, and fast. Li...  \n",
      "...                                                  ...  \n",
      "18719  Vonsland! I swear, THIS IS ACTUALLY A SMALL TO...  \n",
      "18720  This is a fun place to relax, create a paintin...  \n",
      "18721  3 stars for food and service. I have a friend ...  \n",
      "18722  It's wasn't bad as all. It's very slow and eve...  \n",
      "18723  Great selection.. lots of high end options.. b...  \n",
      "\n",
      "[18724 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Select first 50000 rows\n",
    "# first10 = df1\n",
    "\n",
    "\n",
    "df_shuffled = df1.sample(frac=1, random_state=42)\n",
    "df_shuffled = df_shuffled.reset_index(drop=True)\n",
    "\n",
    "#Extract business name and content from the first 50000 rows\n",
    "df2 = df_shuffled[[\"business_name\",\"content\"]]\n",
    "\n",
    "# Create a seperate data frame for label\n",
    "\n",
    "label = [\"is_entertainment\",\"is_traffic\"]\n",
    "labeldf = df3[[\"is_entertainment\",\"is_traffic\"]]\n",
    "print(labeldf)\n",
    "df4 = df3[[\"business_name\",\"content\"]]\n",
    "print(df4)\n",
    "#Extract business name and content\n",
    "#print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noarapoport/opt/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df4[\"text\"] = df4['content'] +\" \"+ df4[\"business_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        They do not make authentic Italian calzones. O...\n",
       "1        They are scammers!!! DO NOT BUY PRODUCTS FROM ...\n",
       "2        Just opened the paper bag to find a burnt croi...\n",
       "3        Needed a quick car wash!!! In the sign $4.19 i...\n",
       "4        This service is convenient, easy, and fast. Li...\n",
       "                               ...                        \n",
       "18719    Vonsland! I swear, THIS IS ACTUALLY A SMALL TO...\n",
       "18720    This is a fun place to relax, create a paintin...\n",
       "18721    3 stars for food and service. I have a friend ...\n",
       "18722    It's wasn't bad as all. It's very slow and eve...\n",
       "18723    Great selection.. lots of high end options.. b...\n",
       "Name: text, Length: 18724, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df4['text'], labeldf[label[0]], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=labeldf[label[0]])\n",
    "\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGdCAYAAADjWSL8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1FUlEQVR4nO3df3SUZ53//9dAhoGwyUjAZDI2baOmiE3adYOGoCuskARO0+hhj6jpjqgsxKWFzQYWi2zXwR9JZU+BPclaKcspSGDjZ4/F1RXHhKNN5YSfsVmBstg9RVo0Q7AOk9DEyTS5v3/05P52GAiZEJq54Pk4J+d0rnnf91zX/Z4cX16Tm3FYlmUJAADAMBPGewIAAACjQYgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABgpZbwncKsMDg7q97//vdLS0uRwOMZ7OgAAYAQsy1JPT4+8Xq8mTBh+r+W2DTG///3vlZOTM97TAAAAo/Daa6/prrvuGrbmtg0xaWlpkt66COnp6WN23mg0qubmZpWWlsrpdI7ZeTE69CO50I/kQj+SC/0Yme7ubuXk5Nj/Oz6c2zbEDH2ElJ6ePuYhJjU1Venp6bwJkwD9SC70I7nQj+RCPxIzkj8F4Q97AQCAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIyUMt4TMFW+/2eKDNz4a8Kv5bdPPjTGswEA4M7DTgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYKSEQsybb76pf/qnf1Jubq6mTJmi9773vfr617+uwcFBu8ayLPn9fnm9Xk2ZMkXz58/X6dOnY84TiUS0evVqzZgxQ1OnTlVFRYUuXLgQUxMKheTz+eR2u+V2u+Xz+XT58uXRrxQAANxWEgox3/72t/Xd735XDQ0NOnPmjDZv3qx/+Zd/UX19vV2zefNmbdmyRQ0NDTp+/Lg8Ho9KSkrU09Nj11RXV2v//v1qamrSoUOHdOXKFZWXl2tgYMCuqaysVEdHhwKBgAKBgDo6OuTz+cZgyQAA4HaQ0NcOHD58WJ/85Cf10ENv/bP59957r/7jP/5DJ06ckPTWLsy2bdu0ceNGLVmyRJK0e/duZWVlad++faqqqlI4HNbOnTu1Z88eLVy4UJLU2NionJwcHTx4UGVlZTpz5owCgYCOHDmioqIiSdKOHTtUXFyss2fPaubMmWN2AQAAgJkSCjEf+9jH9N3vfle/+c1vdN999+l//ud/dOjQIW3btk2SdO7cOQWDQZWWltrHuFwuzZs3T21tbaqqqlJ7e7ui0WhMjdfrVX5+vtra2lRWVqbDhw/L7XbbAUaS5syZI7fbrba2tmuGmEgkokgkYj/u7u6WJEWjUUWj0USWOayhc7kmWDd9Dty8oWvJNU0O9CO50I/kQj9GJpHrk1CI+cpXvqJwOKwPfOADmjhxogYGBvStb31Ln/vc5yRJwWBQkpSVlRVzXFZWls6fP2/XTJo0SdOmTYurGTo+GAwqMzMz7vUzMzPtmqvV1dVp06ZNcePNzc1KTU1NZJkj8o3Zgzcuuo4DBw6M4UwgSS0tLeM9BbwN/Ugu9CO50I/h9fb2jrg2oRDz/e9/X42Njdq3b5/uv/9+dXR0qLq6Wl6vV8uWLbPrHI7Yb3e2LCtu7GpX11yrfrjzbNiwQTU1Nfbj7u5u5eTkqLS0VOnp6SNa30hEo1G1tLToiRMTFBkc3bdYn/KXjdl87nRD/SgpKZHT6Rzv6dzx6EdyoR/JhX6MzNAnKSORUIj5x3/8Rz3++OP67Gc/K0kqKCjQ+fPnVVdXp2XLlsnj8Uh6ayclOzvbPq6rq8venfF4POrv71coFIrZjenq6tLcuXPtmosXL8a9/qVLl+J2eYa4XC65XK64cafTeUveLJFBhyIDowsxvHnH3q3qM0aHfiQX+pFc6MfwErk2Cd2d1NvbqwkTYg+ZOHGifYt1bm6uPB5PzFZZf3+/Wltb7YBSWFgop9MZU9PZ2alTp07ZNcXFxQqHwzp27Jhdc/ToUYXDYbsGAADc2RLaiXn44Yf1rW99S3fffbfuv/9+vfjii9qyZYu+9KUvSXrrI6Dq6mrV1tYqLy9PeXl5qq2tVWpqqiorKyVJbrdby5cv19q1azV9+nRlZGRo3bp1KigosO9WmjVrlhYtWqQVK1Zo+/btkqSVK1eqvLycO5MAAICkBENMfX29nnjiCa1atUpdXV3yer2qqqrSP//zP9s169evV19fn1atWqVQKKSioiI1NzcrLS3Nrtm6datSUlK0dOlS9fX1acGCBdq1a5cmTpxo1+zdu1dr1qyx72KqqKhQQ0PDza4XAADcJhIKMWlpadq2bZt9S/W1OBwO+f1++f3+69ZMnjxZ9fX1Mf9I3tUyMjLU2NiYyPQAAMAdhO9OAgAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYKaEQc++998rhcMT9PProo5Iky7Lk9/vl9Xo1ZcoUzZ8/X6dPn445RyQS0erVqzVjxgxNnTpVFRUVunDhQkxNKBSSz+eT2+2W2+2Wz+fT5cuXb26lAADgtpJQiDl+/Lg6Ozvtn5aWFknSpz/9aUnS5s2btWXLFjU0NOj48ePyeDwqKSlRT0+PfY7q6mrt379fTU1NOnTokK5cuaLy8nINDAzYNZWVlero6FAgEFAgEFBHR4d8Pt9YrBcAANwmUhIpfve73x3z+Mknn9T73vc+zZs3T5Zladu2bdq4caOWLFkiSdq9e7eysrK0b98+VVVVKRwOa+fOndqzZ48WLlwoSWpsbFROTo4OHjyosrIynTlzRoFAQEeOHFFRUZEkaceOHSouLtbZs2c1c+bMsVg3AAAwXEIh5u36+/vV2NiompoaORwOvfLKKwoGgyotLbVrXC6X5s2bp7a2NlVVVam9vV3RaDSmxuv1Kj8/X21tbSorK9Phw4fldrvtACNJc+bMkdvtVltb23VDTCQSUSQSsR93d3dLkqLRqKLR6GiXGWfoXK4J1k2fAzdv6FpyTZMD/Ugu9CO50I+RSeT6jDrE/PCHP9Tly5f1hS98QZIUDAYlSVlZWTF1WVlZOn/+vF0zadIkTZs2La5m6PhgMKjMzMy418vMzLRrrqWurk6bNm2KG29ublZqaurIFzZC35g9OOpjDxw4MIYzgST7o00kB/qRXOhHcqEfw+vt7R1x7ahDzM6dO7V48WJ5vd6YcYfDEfPYsqy4satdXXOt+hudZ8OGDaqpqbEfd3d3KycnR6WlpUpPTx/29RMRjUbV0tKiJ05MUGRw+HVdzyl/2ZjN50431I+SkhI5nc7xns4dj34kF/qRXOjHyAx9kjISowox58+f18GDB/Xcc8/ZYx6PR9JbOynZ2dn2eFdXl7074/F41N/fr1AoFLMb09XVpblz59o1Fy9ejHvNS5cuxe3yvJ3L5ZLL5Yobdzqdt+TNEhl0KDIwuhDDm3fs3ao+Y3ToR3KhH8mFfgwvkWszqn8n5tlnn1VmZqYeeugheyw3N1cejydmm6y/v1+tra12QCksLJTT6Yyp6ezs1KlTp+ya4uJihcNhHTt2zK45evSowuGwXQMAAJDwTszg4KCeffZZLVu2TCkp///hDodD1dXVqq2tVV5envLy8lRbW6vU1FRVVlZKktxut5YvX661a9dq+vTpysjI0Lp161RQUGDfrTRr1iwtWrRIK1as0Pbt2yVJK1euVHl5OXcmAQAAW8Ih5uDBg3r11Vf1pS99Ke659evXq6+vT6tWrVIoFFJRUZGam5uVlpZm12zdulUpKSlaunSp+vr6tGDBAu3atUsTJ060a/bu3as1a9bYdzFVVFSooaFhNOsDAAC3qYRDTGlpqSzr2rcXOxwO+f1++f3+6x4/efJk1dfXq76+/ro1GRkZamxsTHRqAADgDsJ3JwEAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARko4xPzud7/T3/zN32j69OlKTU3Vn//5n6u9vd1+3rIs+f1+eb1eTZkyRfPnz9fp06djzhGJRLR69WrNmDFDU6dOVUVFhS5cuBBTEwqF5PP55Ha75Xa75fP5dPny5dGtEgAA3HYSCjGhUEgf/ehH5XQ69dOf/lQvvfSSnnrqKb3rXe+yazZv3qwtW7aooaFBx48fl8fjUUlJiXp6euya6upq7d+/X01NTTp06JCuXLmi8vJyDQwM2DWVlZXq6OhQIBBQIBBQR0eHfD7fza8YAADcFlISKf72t7+tnJwcPfvss/bYvffea/+3ZVnatm2bNm7cqCVLlkiSdu/eraysLO3bt09VVVUKh8PauXOn9uzZo4ULF0qSGhsblZOTo4MHD6qsrExnzpxRIBDQkSNHVFRUJEnasWOHiouLdfbsWc2cOfNm1w0AAAyXUIj50Y9+pLKyMn36059Wa2ur3vOe92jVqlVasWKFJOncuXMKBoMqLS21j3G5XJo3b57a2tpUVVWl9vZ2RaPRmBqv16v8/Hy1tbWprKxMhw8fltvttgOMJM2ZM0dut1ttbW3XDDGRSESRSMR+3N3dLUmKRqOKRqOJLHNYQ+dyTbBu+hy4eUPXkmuaHOhHcqEfyYV+jEwi1yehEPPKK6/o6aefVk1Njb761a/q2LFjWrNmjVwulz7/+c8rGAxKkrKysmKOy8rK0vnz5yVJwWBQkyZN0rRp0+Jqho4PBoPKzMyMe/3MzEy75mp1dXXatGlT3Hhzc7NSU1MTWeaIfGP24KiPPXDgwBjOBJLU0tIy3lPA29CP5EI/kgv9GF5vb++IaxMKMYODg5o9e7Zqa2slSR/60Id0+vRpPf300/r85z9v1zkcjpjjLMuKG7va1TXXqh/uPBs2bFBNTY39uLu7Wzk5OSotLVV6evqNFzdC0WhULS0teuLEBEUGh1/T9Zzyl43ZfO50Q/0oKSmR0+kc7+nc8ehHcqEfyYV+jMzQJykjkVCIyc7O1gc/+MGYsVmzZukHP/iBJMnj8Uh6ayclOzvbrunq6rJ3Zzwej/r7+xUKhWJ2Y7q6ujR37ly75uLFi3Gvf+nSpbhdniEul0sulytu3Ol03pI3S2TQocjA6EIMb96xd6v6jNGhH8mFfiQX+jG8RK5NQncnffSjH9XZs2djxn7zm9/onnvukSTl5ubK4/HEbJX19/ertbXVDiiFhYVyOp0xNZ2dnTp16pRdU1xcrHA4rGPHjtk1R48eVTgctmsAAMCdLaGdmH/4h3/Q3LlzVVtbq6VLl+rYsWN65pln9Mwzz0h66yOg6upq1dbWKi8vT3l5eaqtrVVqaqoqKyslSW63W8uXL9fatWs1ffp0ZWRkaN26dSooKLDvVpo1a5YWLVqkFStWaPv27ZKklStXqry8nDuTAACApARDzIc//GHt379fGzZs0Ne//nXl5uZq27ZteuSRR+ya9evXq6+vT6tWrVIoFFJRUZGam5uVlpZm12zdulUpKSlaunSp+vr6tGDBAu3atUsTJ060a/bu3as1a9bYdzFVVFSooaHhZtcLAABuEwmFGEkqLy9XeXn5dZ93OBzy+/3y+/3XrZk8ebLq6+tVX19/3ZqMjAw1NjYmOj0AAHCH4LuTAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGSijE+P1+ORyOmB+Px2M/b1mW/H6/vF6vpkyZovnz5+v06dMx54hEIlq9erVmzJihqVOnqqKiQhcuXIipCYVC8vl8crvdcrvd8vl8unz58uhXCQAAbjsJ78Tcf//96uzstH9OnjxpP7d582Zt2bJFDQ0NOn78uDwej0pKStTT02PXVFdXa//+/WpqatKhQ4d05coVlZeXa2BgwK6prKxUR0eHAoGAAoGAOjo65PP5bnKpAADgdpKS8AEpKTG7L0Msy9K2bdu0ceNGLVmyRJK0e/duZWVlad++faqqqlI4HNbOnTu1Z88eLVy4UJLU2NionJwcHTx4UGVlZTpz5owCgYCOHDmioqIiSdKOHTtUXFyss2fPaubMmTezXgAAcJtIOMS8/PLL8nq9crlcKioqUm1trd773vfq3LlzCgaDKi0ttWtdLpfmzZuntrY2VVVVqb29XdFoNKbG6/UqPz9fbW1tKisr0+HDh+V2u+0AI0lz5syR2+1WW1vbdUNMJBJRJBKxH3d3d0uSotGootFoosu8rqFzuSZYN30O3Lyha8k1TQ70I7nQj+RCP0YmkeuTUIgpKirS9773Pd133326ePGivvnNb2ru3Lk6ffq0gsGgJCkrKyvmmKysLJ0/f16SFAwGNWnSJE2bNi2uZuj4YDCozMzMuNfOzMy0a66lrq5OmzZtihtvbm5WampqIssckW/MHhz1sQcOHBjDmUCSWlpaxnsKeBv6kVzoR3KhH8Pr7e0dcW1CIWbx4sX2fxcUFKi4uFjve9/7tHv3bs2ZM0eS5HA4Yo6xLCtu7GpX11yr/kbn2bBhg2pqauzH3d3dysnJUWlpqdLT04dfWAKi0ahaWlr0xIkJigwOv67rOeUvG7P53OmG+lFSUiKn0zne07nj0Y/kQj+SC/0YmaFPUkYi4Y+T3m7q1KkqKCjQyy+/rE996lOS3tpJyc7Otmu6urrs3RmPx6P+/n6FQqGY3Ziuri7NnTvXrrl48WLca126dClul+ftXC6XXC5X3LjT6bwlb5bIoEORgdGFGN68Y+9W9RmjQz+SC/1ILvRjeIlcm5v6d2IikYjOnDmj7Oxs5ebmyuPxxGyT9ff3q7W11Q4ohYWFcjqdMTWdnZ06deqUXVNcXKxwOKxjx47ZNUePHlU4HLZrAAAAEtqJWbdunR5++GHdfffd6urq0je/+U11d3dr2bJlcjgcqq6uVm1trfLy8pSXl6fa2lqlpqaqsrJSkuR2u7V8+XKtXbtW06dPV0ZGhtatW6eCggL7bqVZs2Zp0aJFWrFihbZv3y5JWrlypcrLy7kzCQAA2BIKMRcuXNDnPvc5/eEPf9C73/1uzZkzR0eOHNE999wjSVq/fr36+vq0atUqhUIhFRUVqbm5WWlpafY5tm7dqpSUFC1dulR9fX1asGCBdu3apYkTJ9o1e/fu1Zo1a+y7mCoqKtTQ0DAW6wUAALeJhEJMU1PTsM87HA75/X75/f7r1kyePFn19fWqr6+/bk1GRoYaGxsTmRoAALjD8N1JAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAj3VSIqaurk8PhUHV1tT1mWZb8fr+8Xq+mTJmi+fPn6/Tp0zHHRSIRrV69WjNmzNDUqVNVUVGhCxcuxNSEQiH5fD653W653W75fD5dvnz5ZqYLAABuI6MOMcePH9czzzyjBx54IGZ88+bN2rJlixoaGnT8+HF5PB6VlJSop6fHrqmurtb+/fvV1NSkQ4cO6cqVKyovL9fAwIBdU1lZqY6ODgUCAQUCAXV0dMjn8412ugAA4DYzqhBz5coVPfLII9qxY4emTZtmj1uWpW3btmnjxo1asmSJ8vPztXv3bvX29mrfvn2SpHA4rJ07d+qpp57SwoUL9aEPfUiNjY06efKkDh48KEk6c+aMAoGA/v3f/13FxcUqLi7Wjh079N///d86e/bsGCwbAACYblQh5tFHH9VDDz2khQsXxoyfO3dOwWBQpaWl9pjL5dK8efPU1tYmSWpvb1c0Go2p8Xq9ys/Pt2sOHz4st9utoqIiu2bOnDlyu912DQAAuLOlJHpAU1OTfvWrX+n48eNxzwWDQUlSVlZWzHhWVpbOnz9v10yaNClmB2eoZuj4YDCozMzMuPNnZmbaNVeLRCKKRCL24+7ubklSNBpVNBod6fJuaOhcrgnWTZ8DN2/oWnJNkwP9SC70I7nQj5FJ5PokFGJee+01/f3f/72am5s1efLk69Y5HI6Yx5ZlxY1d7eqaa9UPd566ujpt2rQpbry5uVmpqanDvvZofGP24KiPPXDgwBjOBJLU0tIy3lPA29CP5EI/kgv9GF5vb++IaxMKMe3t7erq6lJhYaE9NjAwoBdeeEENDQ3236sEg0FlZ2fbNV1dXfbujMfjUX9/v0KhUMxuTFdXl+bOnWvXXLx4Me71L126FLfLM2TDhg2qqamxH3d3dysnJ0elpaVKT09PZJnDikajamlp0RMnJigyOHwwu55T/rIxm8+dbqgfJSUlcjqd4z2dOx79SC70I7nQj5EZ+iRlJBIKMQsWLNDJkydjxr74xS/qAx/4gL7yla/ove99rzwej1paWvShD31IktTf36/W1lZ9+9vfliQVFhbK6XSqpaVFS5culSR1dnbq1KlT2rx5sySpuLhY4XBYx44d00c+8hFJ0tGjRxUOh+2gczWXyyWXyxU37nQ6b8mbJTLoUGRgdCGGN+/Yu1V9xujQj+RCP5IL/RheItcmoRCTlpam/Pz8mLGpU6dq+vTp9nh1dbVqa2uVl5envLw81dbWKjU1VZWVlZIkt9ut5cuXa+3atZo+fboyMjK0bt06FRQU2H8oPGvWLC1atEgrVqzQ9u3bJUkrV65UeXm5Zs6cmciUAQDAbSrhP+y9kfXr16uvr0+rVq1SKBRSUVGRmpublZaWZtds3bpVKSkpWrp0qfr6+rRgwQLt2rVLEydOtGv27t2rNWvW2HcxVVRUqKGhYaynCwAADHXTIeb555+PeexwOOT3++X3+697zOTJk1VfX6/6+vrr1mRkZKixsfFmpwcAAG5TfHcSAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGCkhELM008/rQceeEDp6elKT09XcXGxfvrTn9rPW5Ylv98vr9erKVOmaP78+Tp9+nTMOSKRiFavXq0ZM2Zo6tSpqqio0IULF2JqQqGQfD6f3G633G63fD6fLl++PPpVAgCA205CIeauu+7Sk08+qRMnTujEiRP6xCc+oU9+8pN2UNm8ebO2bNmihoYGHT9+XB6PRyUlJerp6bHPUV1drf3796upqUmHDh3SlStXVF5eroGBAbumsrJSHR0dCgQCCgQC6ujokM/nG6MlAwCA20FKIsUPP/xwzONvfetbevrpp3XkyBF98IMf1LZt27Rx40YtWbJEkrR7925lZWVp3759qqqqUjgc1s6dO7Vnzx4tXLhQktTY2KicnBwdPHhQZWVlOnPmjAKBgI4cOaKioiJJ0o4dO1RcXKyzZ89q5syZY7FuAABguIRCzNsNDAzoP//zP/XGG2+ouLhY586dUzAYVGlpqV3jcrk0b948tbW1qaqqSu3t7YpGozE1Xq9X+fn5amtrU1lZmQ4fPiy3220HGEmaM2eO3G632trarhtiIpGIIpGI/bi7u1uSFI1GFY1GR7vMOEPnck2wbvocuHlD15JrmhzoR3KhH8mFfoxMItcn4RBz8uRJFRcX609/+pP+7M/+TPv379cHP/hBtbW1SZKysrJi6rOysnT+/HlJUjAY1KRJkzRt2rS4mmAwaNdkZmbGvW5mZqZdcy11dXXatGlT3Hhzc7NSU1MTW+QIfGP24KiPPXDgwBjOBJLU0tIy3lPA29CP5EI/kgv9GF5vb++IaxMOMTNnzlRHR4cuX76sH/zgB1q2bJlaW1vt5x0OR0y9ZVlxY1e7uuZa9Tc6z4YNG1RTU2M/7u7uVk5OjkpLS5Wenn7DdY1UNBpVS0uLnjgxQZHB4dd1Paf8ZWM2nzvdUD9KSkrkdDrHezp3PPqRXOhHcqEfIzP0ScpIJBxiJk2apPe///2SpNmzZ+v48eP613/9V33lK1+R9NZOSnZ2tl3f1dVl7854PB719/crFArF7MZ0dXVp7ty5ds3FixfjXvfSpUtxuzxv53K55HK54sadTuctebNEBh2KDIwuxPDmHXu3qs8YHfqRXOhHcqEfw0vk2tz0vxNjWZYikYhyc3Pl8Xhitsn6+/vV2tpqB5TCwkI5nc6Yms7OTp06dcquKS4uVjgc1rFjx+yao0ePKhwO2zUAAAAJ7cR89atf1eLFi5WTk6Oenh41NTXp+eefVyAQkMPhUHV1tWpra5WXl6e8vDzV1tYqNTVVlZWVkiS3263ly5dr7dq1mj59ujIyMrRu3ToVFBTYdyvNmjVLixYt0ooVK7R9+3ZJ0sqVK1VeXs6dSQAAwJZQiLl48aJ8Pp86Ozvldrv1wAMPKBAIqKSkRJK0fv169fX1adWqVQqFQioqKlJzc7PS0tLsc2zdulUpKSlaunSp+vr6tGDBAu3atUsTJ060a/bu3as1a9bYdzFVVFSooaFhLNYLAABuEwmFmJ07dw77vMPhkN/vl9/vv27N5MmTVV9fr/r6+uvWZGRkqLGxMZGpAQCAOwzfnQQAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIyX03UkYG/c+/pNRH/vbJx8aw5kAAGAudmIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgpIRCTF1dnT784Q8rLS1NmZmZ+tSnPqWzZ8/G1FiWJb/fL6/XqylTpmj+/Pk6ffp0TE0kEtHq1as1Y8YMTZ06VRUVFbpw4UJMTSgUks/nk9vtltvtls/n0+XLl0e3SgAAcNtJKMS0trbq0Ucf1ZEjR9TS0qI333xTpaWleuONN+yazZs3a8uWLWpoaNDx48fl8XhUUlKinp4eu6a6ulr79+9XU1OTDh06pCtXrqi8vFwDAwN2TWVlpTo6OhQIBBQIBNTR0SGfzzcGSwYAALeDlESKA4FAzONnn31WmZmZam9v18c//nFZlqVt27Zp48aNWrJkiSRp9+7dysrK0r59+1RVVaVwOKydO3dqz549WrhwoSSpsbFROTk5OnjwoMrKynTmzBkFAgEdOXJERUVFkqQdO3aouLhYZ8+e1cyZM8di7QAAwGAJhZirhcNhSVJGRoYk6dy5cwoGgyotLbVrXC6X5s2bp7a2NlVVVam9vV3RaDSmxuv1Kj8/X21tbSorK9Phw4fldrvtACNJc+bMkdvtVltb2zVDTCQSUSQSsR93d3dLkqLRqKLR6M0sM8bQuVwTrDE752heH28Zuh5cl+RAP5IL/Ugu9GNkErk+ow4xlmWppqZGH/vYx5Sfny9JCgaDkqSsrKyY2qysLJ0/f96umTRpkqZNmxZXM3R8MBhUZmZm3GtmZmbaNVerq6vTpk2b4sabm5uVmpqa4Opu7BuzB8f8nCNx4MCBcXndZNfS0jLeU8Db0I/kQj+SC/0YXm9v74hrRx1iHnvsMf3617/WoUOH4p5zOBwxjy3Lihu72tU116of7jwbNmxQTU2N/bi7u1s5OTkqLS1Venr6sK+diGg0qpaWFj1xYoIig8Ov6VY45S97x18zmQ31o6SkRE6nc7ync8ejH8mFfiQX+jEyQ5+kjMSoQszq1av1ox/9SC+88ILuuusue9zj8Uh6ayclOzvbHu/q6rJ3Zzwej/r7+xUKhWJ2Y7q6ujR37ly75uLFi3Gve+nSpbhdniEul0sulytu3Ol03pI3S2TQocjAOx9ieONf263qM0aHfiQX+pFc6MfwErk2Cd2dZFmWHnvsMT333HP6+c9/rtzc3Jjnc3Nz5fF4YrbK+vv71draageUwsJCOZ3OmJrOzk6dOnXKrikuLlY4HNaxY8fsmqNHjyocDts1AADgzpbQTsyjjz6qffv26b/+67+UlpZm/32K2+3WlClT5HA4VF1drdraWuXl5SkvL0+1tbVKTU1VZWWlXbt8+XKtXbtW06dPV0ZGhtatW6eCggL7bqVZs2Zp0aJFWrFihbZv3y5JWrlypcrLy7kzCQAASEowxDz99NOSpPnz58eMP/vss/rCF74gSVq/fr36+vq0atUqhUIhFRUVqbm5WWlpaXb91q1blZKSoqVLl6qvr08LFizQrl27NHHiRLtm7969WrNmjX0XU0VFhRoaGkazRgAAcBtKKMRY1o1vK3Y4HPL7/fL7/detmTx5surr61VfX3/dmoyMDDU2NiYyPQAAcAfhu5MAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMlHGJeeOEFPfzww/J6vXI4HPrhD38Y87xlWfL7/fJ6vZoyZYrmz5+v06dPx9REIhGtXr1aM2bM0NSpU1VRUaELFy7E1IRCIfl8Prndbrndbvl8Pl2+fDnhBQIAgNtTSqIHvPHGG3rwwQf1xS9+UX/9138d9/zmzZu1ZcsW7dq1S/fdd5+++c1vqqSkRGfPnlVaWpokqbq6Wj/+8Y/V1NSk6dOna+3atSovL1d7e7smTpwoSaqsrNSFCxcUCAQkSStXrpTP59OPf/zjm1mv8e59/CejPva3Tz40hjMBAGB8JRxiFi9erMWLF1/zOcuytG3bNm3cuFFLliyRJO3evVtZWVnat2+fqqqqFA6HtXPnTu3Zs0cLFy6UJDU2NionJ0cHDx5UWVmZzpw5o0AgoCNHjqioqEiStGPHDhUXF+vs2bOaOXPmaNcLAABuEwmHmOGcO3dOwWBQpaWl9pjL5dK8efPU1tamqqoqtbe3KxqNxtR4vV7l5+erra1NZWVlOnz4sNxutx1gJGnOnDlyu91qa2u7ZoiJRCKKRCL24+7ubklSNBpVNBodszUOncs1wRqzc75TxvI6JIuhNd2OazMR/Ugu9CO50I+RSeT6jGmICQaDkqSsrKyY8aysLJ0/f96umTRpkqZNmxZXM3R8MBhUZmZm3PkzMzPtmqvV1dVp06ZNcePNzc1KTU1NfDE38I3Zg2N+zlvtwIED4z2FW6alpWW8p4C3oR/JhX4kF/oxvN7e3hHXjmmIGeJwOGIeW5YVN3a1q2uuVT/ceTZs2KCamhr7cXd3t3JyclRaWqr09PREpj+saDSqlpYWPXFigiKDw68p2Zzyl433FMbcUD9KSkrkdDrHezp3PPqRXOhHcqEfIzP0ScpIjGmI8Xg8kt7aScnOzrbHu7q67N0Zj8ej/v5+hUKhmN2Yrq4uzZ071665ePFi3PkvXboUt8szxOVyyeVyxY07nc5b8maJDDoUGTArxNzOvzS3qs8YHfqRXOhHcqEfw0vk2ozpvxOTm5srj8cTs1XW39+v1tZWO6AUFhbK6XTG1HR2durUqVN2TXFxscLhsI4dO2bXHD16VOFw2K4BAAB3toR3Yq5cuaL/+7//sx+fO3dOHR0dysjI0N13363q6mrV1tYqLy9PeXl5qq2tVWpqqiorKyVJbrdby5cv19q1azV9+nRlZGRo3bp1KigosO9WmjVrlhYtWqQVK1Zo+/btkt66xbq8vJw7kwAAgKRRhJgTJ07or/7qr+zHQ3+HsmzZMu3atUvr169XX1+fVq1apVAopKKiIjU3N9v/Rowkbd26VSkpKVq6dKn6+vq0YMEC7dq1y/43YiRp7969WrNmjX0XU0VFhRoaGka9UAAAcHtJOMTMnz9flnX924sdDof8fr/8fv91ayZPnqz6+nrV19dftyYjI0ONjY2JTg8AANwh+O4kAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACOljPcE8M659/GfjPrY3z750BjOBACAm8dODAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYia8dwIjwlQUAgGTDTgwAADASIQYAABiJEAMAAIzE38TgluPvaQAAtwI7MQAAwEhJH2K+853vKDc3V5MnT1ZhYaF++ctfjveUAABAEkjqj5O+//3vq7q6Wt/5znf00Y9+VNu3b9fixYv10ksv6e677x7v6eEdcKOPolwTLW3+iJTv/5kiA46Y5/goCgBub0kdYrZs2aLly5frb//2byVJ27Zt089+9jM9/fTTqqurG+fZIdnxtzgAcHtL2hDT39+v9vZ2Pf744zHjpaWlamtri6uPRCKKRCL243A4LEn64x//qGg0Ombzikaj6u3tVUp0ggYGHTc+ALdUyqCl3t7BMe/H+9f9vzE7VyKOblgwLq87VoZ+P15//XU5nc7xns4dj34kF/oxMj09PZIky7JuWJu0IeYPf/iDBgYGlJWVFTOelZWlYDAYV19XV6dNmzbFjefm5t6yOSI5VI73BMbQjKfGewYAkBx6enrkdruHrUnaEDPE4Yj9f9eWZcWNSdKGDRtUU1NjPx4cHNQf//hHTZ8+/Zr1o9Xd3a2cnBy99tprSk9PH7PzYnToR3KhH8mFfiQX+jEylmWpp6dHXq/3hrVJG2JmzJihiRMnxu26dHV1xe3OSJLL5ZLL5YoZe9e73nXL5peens6bMInQj+RCP5IL/Ugu9OPGbrQDMyRpb7GeNGmSCgsL1dLSEjPe0tKiuXPnjtOsAABAskjanRhJqqmpkc/n0+zZs1VcXKxnnnlGr776qr785S+P99QAAMA4S+oQ85nPfEavv/66vv71r6uzs1P5+fk6cOCA7rnnnnGbk8vl0te+9rW4j64wPuhHcqEfyYV+JBf6MfYc1kjuYQIAAEgySfs3MQAAAMMhxAAAACMRYgAAgJEIMQAAwEiEmAR85zvfUW5uriZPnqzCwkL98pe/HO8p3Xb8fr8cDkfMj8fjsZ+3LEt+v19er1dTpkzR/Pnzdfr06ZhzRCIRrV69WjNmzNDUqVNVUVGhCxcuvNNLMdYLL7yghx9+WF6vVw6HQz/84Q9jnh+rHoRCIfl8Prndbrndbvl8Pl2+fPkWr848N+rHF77whbjfmTlz5sTU0I+xUVdXpw9/+MNKS0tTZmamPvWpT+ns2bMxNfx+vLMIMSP0/e9/X9XV1dq4caNefPFF/eVf/qUWL16sV199dbyndtu5//771dnZaf+cPHnSfm7z5s3asmWLGhoadPz4cXk8HpWUlNhfGCZJ1dXV2r9/v5qamnTo0CFduXJF5eXlGhgYGI/lGOeNN97Qgw8+qIaGhms+P1Y9qKysVEdHhwKBgAKBgDo6OuTz+W75+kxzo35I0qJFi2J+Zw4cOBDzPP0YG62trXr00Ud15MgRtbS06M0331RpaaneeOMNu4bfj3eYhRH5yEc+Yn35y1+OGfvABz5gPf744+M0o9vT1772NevBBx+85nODg4OWx+OxnnzySXvsT3/6k+V2u63vfve7lmVZ1uXLly2n02k1NTXZNb/73e+sCRMmWIFA4JbO/XYkydq/f7/9eKx68NJLL1mSrCNHjtg1hw8ftiRZ//u//3uLV2Wuq/thWZa1bNky65Of/OR1j6Eft05XV5clyWptbbUsi9+P8cBOzAj09/ervb1dpaWlMeOlpaVqa2sbp1ndvl5++WV5vV7l5ubqs5/9rF555RVJ0rlz5xQMBmP64HK5NG/ePLsP7e3tikajMTVer1f5+fn0agyMVQ8OHz4st9utoqIiu2bOnDlyu930aRSef/55ZWZm6r777tOKFSvU1dVlP0c/bp1wOCxJysjIkMTvx3ggxIzAH/7wBw0MDMR98WRWVlbcF1Ti5hQVFel73/uefvazn2nHjh0KBoOaO3euXn/9dftaD9eHYDCoSZMmadq0adetweiNVQ+CwaAyMzPjzp+ZmUmfErR48WLt3btXP//5z/XUU0/p+PHj+sQnPqFIJCKJftwqlmWppqZGH/vYx5Sfny+J34/xkNRfO5BsHA5HzGPLsuLGcHMWL15s/3dBQYGKi4v1vve9T7t377b/WHE0faBXY2ssenCtevqUuM985jP2f+fn52v27Nm655579JOf/ERLliy57nH04+Y89thj+vWvf61Dhw7FPcfvxzuHnZgRmDFjhiZOnBiXgLu6uuISN8bW1KlTVVBQoJdfftm+S2m4Png8HvX39ysUCl23BqM3Vj3weDy6ePFi3PkvXbpEn25Sdna27rnnHr388suS6MetsHr1av3oRz/SL37xC9111132OL8f7zxCzAhMmjRJhYWFamlpiRlvaWnR3Llzx2lWd4ZIJKIzZ84oOztbubm58ng8MX3o7+9Xa2ur3YfCwkI5nc6Yms7OTp06dYpejYGx6kFxcbHC4bCOHTtm1xw9elThcJg+3aTXX39dr732mrKzsyXRj7FkWZYee+wxPffcc/r5z3+u3NzcmOf5/RgH4/LnxAZqamqynE6ntXPnTuull16yqqurralTp1q//e1vx3tqt5W1a9dazz//vPXKK69YR44cscrLy620tDT7Oj/55JOW2+22nnvuOevkyZPW5z73OSs7O9vq7u62z/HlL3/Zuuuuu6yDBw9av/rVr6xPfOIT1oMPPmi9+eab47Uso/T09Fgvvvii9eKLL1qSrC1btlgvvviidf78ecuyxq4HixYtsh544AHr8OHD1uHDh62CggKrvLz8HV9vshuuHz09PdbatWuttrY269y5c9YvfvELq7i42HrPe95DP26Bv/u7v7Pcbrf1/PPPW52dnfZPb2+vXcPvxzuLEJOAf/u3f7Puuecea9KkSdZf/MVf2LfVYex85jOfsbKzsy2n02l5vV5ryZIl1unTp+3nBwcHra997WuWx+OxXC6X9fGPf9w6efJkzDn6+vqsxx57zMrIyLCmTJlilZeXW6+++uo7vRRj/eIXv7Akxf0sW7bMsqyx68Hrr79uPfLII1ZaWpqVlpZmPfLII1YoFHqHVmmO4frR29trlZaWWu9+97stp9Np3X333dayZcvirjX9GBvX6oMk69lnn7Vr+P14Zzksy7Le6d0fAACAm8XfxAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgpP8PUlurfSzXX/gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noarapoport/opt/anaconda3/envs/tf/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2360: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = 250,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = 250,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = 250,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0bcbe352eb4d08bc40fa00e681b6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "      \n",
    "      super(BERT_Arch, self).__init__()\n",
    "\n",
    "      self.bert = bert \n",
    "      \n",
    "      # dropout layer\n",
    "      self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "      # relu activation function\n",
    "      self.relu =  nn.ReLU()\n",
    "\n",
    "      # dense layer 1\n",
    "      self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "      # dense layer 2 (Output layer)\n",
    "      self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "      #softmax activation function\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "      #pass the inputs to the model  \n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "      \n",
    "      x = self.fc1(cls_hs)\n",
    "\n",
    "      x = self.relu(x)\n",
    "\n",
    "      x = self.dropout(x)\n",
    "\n",
    "      # output layer\n",
    "      x = self.fc2(x)\n",
    "      \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 10:24:10.438958: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/noarapoport/opt/anaconda3/envs/tf/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [0.58027096 3.61445119]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "compute the class weights\n",
    "class_weights = compute_class_weight(class_weight = \"balanced\", classes= np.unique(train_labels), y= train_labels)\n",
    "\n",
    "print(\"Class Weights:\",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list of class weights to a tensor\n",
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "# push to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# define the loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch]\n",
    " \n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "  print(\"\\nEvaluating...\")\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "    # Progress update every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      \n",
    "      # Calculate elapsed time in minutes.\n",
    "      elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "      # Report progress.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "\n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 10\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zt/3z6q8x1d1zjffbdqfbv3hw800000gn/T/ipykernel_29513/2583630083.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/zt/3z6q8x1d1zjffbdqfbv3hw800000gn/T/ipykernel_29513/2212538583.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# push the batch to gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/zt/3z6q8x1d1zjffbdqfbv3hw800000gn/T/ipykernel_29513/2212538583.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# push the batch to gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
